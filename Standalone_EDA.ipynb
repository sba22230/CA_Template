{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Untitled\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqPkgs = ['matplotlib', 'scipy', 'statsmodels', 'pandas', 'numpy', 'functools', 'ipython'\n",
    ",'ipywidgets', 'seaborn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absl-py', 'anyio', 'argon2-cffi', 'argon2-cffi-bindings', 'arrow', 'asttokens', 'astunparse', 'attrs', 'auxlib', 'Babel', 'backcall', 'beautifulsoup4', 'bleach', 'cachetools', 'certifi', 'cffi', 'charset-normalizer', 'colorama', 'comm', 'conda', 'contourpy', 'cycler', 'cytoolz', 'debugpy', 'decorator', 'defusedxml', 'distlib', 'entrypoints', 'executing', 'fastjsonschema', 'filelock', 'flatbuffers', 'fonttools', 'fqdn', 'gast', 'google-auth', 'google-auth-oauthlib', 'google-pasta', 'grpcio', 'h5py', 'idna', 'importlib-metadata', 'ipykernel', 'ipyparallel', 'ipython', 'ipython-genutils', 'ipywidgets', 'isoduration', 'jedi', 'Jinja2', 'json5', 'jsonpointer', 'jsonschema', 'jupyter', 'jupyter-console', 'jupyter-events', 'jupyter-server', 'jupyter_client', 'jupyter_core', 'jupyter_server_terminals', 'jupyterlab', 'jupyterlab-pygments', 'jupyterlab-widgets', 'jupyterlab_server', 'keras', 'Keras-Preprocessing', 'kiwisolver', 'libclang', 'Markdown', 'MarkupSafe', 'matplotlib', 'matplotlib-inline', 'mistune', 'mpi4py', 'nbclassic', 'nbclient', 'nbconvert', 'nbformat', 'nest-asyncio', 'notebook', 'notebook_shim', 'numpy', 'oauthlib', 'opt-einsum', 'packaging', 'pandas', 'pandocfilters', 'parso', 'patsy', 'pickleshare', 'Pillow', 'platformdirs', 'prometheus-client', 'prompt-toolkit', 'protobuf', 'psutil', 'pure-eval', 'pyarrow', 'pyasn1', 'pyasn1-modules', 'pycosat', 'pycparser', 'Pygments', 'pyparsing', 'pyrsistent', 'python-dateutil', 'python-json-logger', 'pytz', 'pywin32', 'pywinpty', 'PyYAML', 'pyzmq', 'qtconsole', 'QtPy', 'requests', 'requests-oauthlib', 'rfc3339-validator', 'rfc3986-validator', 'rsa', 'ruamel.yaml', 'ruamel.yaml.clib', 'scipy', 'seaborn', 'Send2Trash', 'six', 'sniffio', 'soupsieve', 'stack-data', 'statsmodels', 'tensorboard', 'tensorboard-data-server', 'tensorboard-plugin-wit', 'tensorflow', 'tensorflow-estimator', 'tensorflow-io-gcs-filesystem', 'termcolor', 'terminado', 'tinycss2', 'tomli', 'toolz', 'torch', 'torchaudio', 'torchvision', 'tornado', 'tqdm', 'traitlets', 'typing_extensions', 'uri-template', 'urllib3', 'virtualenv', 'voila', 'wcwidth', 'webcolors', 'webencodings', 'websocket-client', 'websockets', 'Werkzeug', 'widgetsnbextension', 'wordcloud', 'wrapt', 'zipp']\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])\n",
    "installed_packages = [r.decode().split('==')[0] for r in reqs.split()]\n",
    "print(installed_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['functools']\n"
     ]
    }
   ],
   "source": [
    "instPks = list(set(reqPkgs) - set(installed_packages))\n",
    "print(instPks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install functools'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in instPks:\n",
    "    display('%pip install ' + p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\program files\\python39\\lib\\site-packages (from seaborn) (3.6.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\program files\\python39\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\program files\\python39\\lib\\site-packages (from seaborn) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\program files\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python39\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting functools\n",
      "  Using cached functools-0.5.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: functools\n",
      "  Building wheel for functools (setup.py): started\n",
      "  Building wheel for functools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for functools\n",
      "Failed to build functools\n",
      "Installing collected packages: functools\n",
      "  Running setup.py install for functools: started\n",
      "  Running setup.py install for functools: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [32 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-3.9\n",
      "      copying functools.py -> build\\lib.win-amd64-3.9\n",
      "      running build_ext\n",
      "      building '_functools' extension\n",
      "      creating build\\temp.win-amd64-3.9\n",
      "      creating build\\temp.win-amd64-3.9\\Release\n",
      "      creating build\\temp.win-amd64-3.9\\Release\\src\n",
      "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.35.32215\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ic:\\Program Files\\Python39\\include -Ic:\\Program Files\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.35.32215\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.35.32215\\ATLMFC\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tcsrc\\compose.c /Fobuild\\temp.win-amd64-3.9\\Release\\src\\compose.obj\n",
      "      compose.c\n",
      "      src\\compose.c(57): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "      src\\compose.c(96): error C2039: 'ob_type': is not a member of 'compose'\n",
      "      src\\compose.c(44): note: see declaration of 'compose'\n",
      "      src\\compose.c(137): warning C4013: 'PyString_FromFormat' undefined; assuming extern returning int\n",
      "      src\\compose.c(138): warning C4013: 'PyString_AsString' undefined; assuming extern returning int\n",
      "      src\\compose.c(138): warning C4047: '=': 'PyObject *' differs in levels of indirection from 'int'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'Py_ssize_t' differs in levels of indirection from 'char [8]'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'Py_ssize_t' differs in levels of indirection from 'destructor'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'PyNumberMethods *' differs in levels of indirection from 'reprfunc'\n",
      "      src\\compose.c(160): warning C4113: 'ternaryfunc' differs in parameter lists from 'reprfunc'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'const char *' differs in levels of indirection from 'unsigned long'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'traverseproc' differs in levels of indirection from 'const char *'\n",
      "      src\\compose.c(168): warning C4113: 'traverseproc' differs in parameter lists from 'inquiry'\n",
      "      src\\compose.c(179): warning C4113: 'PyObject *(__cdecl *)(PyObject *,PyObject *)' differs in parameter lists from 'descrsetfunc'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'descrsetfunc' differs in levels of indirection from 'PyObject *(__cdecl *)(PyObject *,PyObject *)'\n",
      "      src\\compose.c(184): warning C4113: 'PyObject *(__cdecl *)(PyTypeObject *,PyObject *,PyObject *)' differs in parameter lists from 'freefunc'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'freefunc' differs in levels of indirection from 'PyObject *(__cdecl *)(PyTypeObject *,PyObject *,PyObject *)'\n",
      "      src\\compose.c(185): warning C4133: 'initializing': incompatible types - from 'void (__cdecl *)(void *)' to 'inquiry'\n",
      "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.35.32215\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for functools\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for functools did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [32 lines of output]\n",
      "      running install\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-3.9\n",
      "      copying functools.py -> build\\lib.win-amd64-3.9\n",
      "      running build_ext\n",
      "      building '_functools' extension\n",
      "      creating build\\temp.win-amd64-3.9\n",
      "      creating build\\temp.win-amd64-3.9\\Release\n",
      "      creating build\\temp.win-amd64-3.9\\Release\\src\n",
      "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.35.32215\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ic:\\Program Files\\Python39\\include -Ic:\\Program Files\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.35.32215\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.35.32215\\ATLMFC\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tcsrc\\compose.c /Fobuild\\temp.win-amd64-3.9\\Release\\src\\compose.obj\n",
      "      compose.c\n",
      "      src\\compose.c(57): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "      src\\compose.c(96): error C2039: 'ob_type': is not a member of 'compose'\n",
      "      src\\compose.c(44): note: see declaration of 'compose'\n",
      "      src\\compose.c(137): warning C4013: 'PyString_FromFormat' undefined; assuming extern returning int\n",
      "      src\\compose.c(138): warning C4013: 'PyString_AsString' undefined; assuming extern returning int\n",
      "      src\\compose.c(138): warning C4047: '=': 'PyObject *' differs in levels of indirection from 'int'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'Py_ssize_t' differs in levels of indirection from 'char [8]'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'Py_ssize_t' differs in levels of indirection from 'destructor'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'PyNumberMethods *' differs in levels of indirection from 'reprfunc'\n",
      "      src\\compose.c(160): warning C4113: 'ternaryfunc' differs in parameter lists from 'reprfunc'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'const char *' differs in levels of indirection from 'unsigned long'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'traverseproc' differs in levels of indirection from 'const char *'\n",
      "      src\\compose.c(168): warning C4113: 'traverseproc' differs in parameter lists from 'inquiry'\n",
      "      src\\compose.c(179): warning C4113: 'PyObject *(__cdecl *)(PyObject *,PyObject *)' differs in parameter lists from 'descrsetfunc'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'descrsetfunc' differs in levels of indirection from 'PyObject *(__cdecl *)(PyObject *,PyObject *)'\n",
      "      src\\compose.c(184): warning C4113: 'PyObject *(__cdecl *)(PyTypeObject *,PyObject *,PyObject *)' differs in parameter lists from 'freefunc'\n",
      "      src\\compose.c(143): warning C4047: 'initializing': 'freefunc' differs in levels of indirection from 'PyObject *(__cdecl *)(PyTypeObject *,PyObject *,PyObject *)'\n",
      "      src\\compose.c(185): warning C4133: 'initializing': incompatible types - from 'void (__cdecl *)(void *)' to 'inquiry'\n",
      "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.35.32215\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> functools\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: statsmodels in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (0.13.5)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\program files\\python39\\lib\\site-packages (from statsmodels) (23.0)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\program files\\python39\\lib\\site-packages (from statsmodels) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\program files\\python39\\lib\\site-packages (from statsmodels) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\program files\\python39\\lib\\site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python39\\lib\\site-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n",
      "Requirement already satisfied: six in c:\\program files\\python39\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\program files\\python39\\lib\\site-packages (from scipy) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn\n",
    "%pip install functools\n",
    "%pip install statsmodels\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from functools import partial\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interactive,fixed\n",
    "import operator\n",
    "from IPython.display import Javascript, display,HTML\n",
    "from ipywidgets import widgets, VBox\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import getpass\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ConfUtility():   \n",
    "    @staticmethod\n",
    "    def parse_yaml(input_file):\n",
    "        import yaml\n",
    "        yaml_dict = {}\n",
    "        with open (input_file,'r') as fin:\n",
    "            try:\n",
    "                yaml_dict = yaml.load(fin)\n",
    "            except Exception as ex:\n",
    "                print (ex)\n",
    "        return yaml_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_to_htmllist(dc, include_list=None):\n",
    "        dc2 = {}\n",
    "        output_formatting = {'Target':'Target variable is ','CategoricalColumns':'Categorical Columns are ',\n",
    "                           'NumericalColumns':'Numerical Columns are '}\n",
    "        for each in dc.keys():\n",
    "            if not include_list or each in include_list:\n",
    "                if isinstance(dc[each],  collections.Iterable) and not isinstance(dc[each], str):\n",
    "                    dc2[each] = ', \\n'.join(val for val in dc[each])\n",
    "                else:\n",
    "                    dc2[each] = dc[each]\n",
    "        html_list = \"<ul>{}</ul>\"\n",
    "        html_list_entry = \"<li>{}</li>\"\n",
    "        output3 = ''\n",
    "\n",
    "        for each in set(include_list)|set(dc2.keys()):\n",
    "            output3 += html_list_entry.format(output_formatting[each]+dc2[each])\n",
    "        html_list = html_list.format(output3)\n",
    "        return HTML(html_list)\n",
    "    \n",
    "class InteractionAnalytics():\n",
    "    @staticmethod\n",
    "    def rank_associations(df, conf_dict, col1, col2, col3):        \n",
    "        try:\n",
    "            col2 = int(col2)\n",
    "            col3 = int(col3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Passed Variable is Numerical\n",
    "        if (col1 in NumericalColumns):\n",
    "            fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "            if len(NumericalColumns)>1:\n",
    "                \n",
    "                # Interaction with numerical variables\n",
    "                df2 = df[NumericalColumns]\n",
    "                corrdf = df2.corr()\n",
    "                corrdf = abs(corrdf) \n",
    "                corrdf2 = corrdf[corrdf.index==col1].reset_index()[[each for each in corrdf.columns \\\n",
    "                                                      if col1 not in each]].unstack().sort_values(kind=\"quicksort\", \n",
    "                                                                                                  ascending=False).head(col2)\n",
    "                corrdf2 = corrdf2.reset_index()\n",
    "                corrdf2.columns = ['level0','level1','rsq']\n",
    "                corrdf2.set_index('level0', inplace=True)\n",
    "                corrdf2[['rsq']].plot(kind='bar', ax=ax1)\n",
    "                ax1.legend().set_visible(False)\n",
    "                ax1.set_xlabel('Absolute Correlation')\n",
    "                ax1.set_title('Top {} Associated Numeric Variables'.format(str(col2)))\n",
    "                # Interaction with categorical variables\n",
    "                etasquared_dict = {}\n",
    "            if len(CategoricalColumns) >= 1:\n",
    "                for each in CategoricalColumns:\n",
    "                    mod = ols('{} ~ C({})'.format(col1, each),data=df[[col1,each]],missing='drop').fit()\n",
    "                    aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "                    esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "                    etasquared_dict[each] = esq_sm\n",
    "\n",
    "                topk_esq = pd.DataFrame.from_dict(etasquared_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col3).reset_index().set_index('level_1')\n",
    "                topk_esq.columns = ['level_0', 'EtaSquared']\n",
    "                topk_esq[['EtaSquared']].plot(kind='bar',ax=ax2)\n",
    "                ax2.legend().set_visible(False)\n",
    "                ax2.set_xlabel('Eta-squared values')\n",
    "                ax2.set_title('Top {}  Associated Categoric Variables'.format(str(col2)))\n",
    "        # Passed Variable is Categorical\n",
    "        else:\n",
    "            #Interaction with numerical variables\n",
    "            fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "            if len(NumericalColumns) >= 1:\n",
    "                etasquared_dict = {}\n",
    "                for each in NumericalColumns:\n",
    "                    mod = ols('{} ~ C({})'.format(each, col1), data = df[[col1,each]]).fit()\n",
    "                    aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "                    esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "                    etasquared_dict[each] = esq_sm\n",
    "\n",
    "                topk_esq = pd.DataFrame.from_dict(etasquared_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col2).reset_index().set_index('level_1')\n",
    "                topk_esq.columns = ['level_0','EtaSquared']\n",
    "                topk_esq[['EtaSquared']].plot(kind='bar',ax=ax1)\n",
    "                ax1.legend().set_visible(False)\n",
    "                ax1.set_xlabel('Eta-squared values')\n",
    "                ax1.set_title('Top {} Associated Numeric Variables'.format(str(col2)))\n",
    "\n",
    "            # Interaction with categorical variables\n",
    "            cramer_dict = {}\n",
    "            if len(CategoricalColumns)>1:\n",
    "                for each in CategoricalColumns:\n",
    "                    if each !=col1:\n",
    "                        tbl = pd.crosstab(df[col1], df[each])\n",
    "                        chisq = stats.chi2_contingency(tbl, correction=False)[0]\n",
    "                        try:\n",
    "                            cramer = np.sqrt(chisq/sum(tbl))\n",
    "                        except:\n",
    "                            cramer = np.sqrt(chisq/tbl.as_matrix().sum())\n",
    "                            pass\n",
    "                        cramer_dict[each] = cramer\n",
    "\n",
    "                topk_cramer = pd.DataFrame.from_dict(cramer_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col3).reset_index().set_index('level_1')\n",
    "                topk_cramer.columns = ['level_0','CramersV']\n",
    "                topk_cramer[['CramersV']].plot(kind='bar',ax=ax2)\n",
    "                ax2.legend().set_visible(False)\n",
    "                ax2.set_xlabel(\"Cramer's V\")\n",
    "                ax2.set_title('Top {} Associated Categoric Variables'.format(str(col2)))\n",
    "        \n",
    "    @staticmethod\n",
    "    def NoLabels(x):\n",
    "        return ''\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_relations(df, col1, col2):\n",
    "        if col1 != col2:\n",
    "            df2 = df[(df[col1].isin(df[col1].value_counts().head(10).index.tolist()))&(df[col2].isin(df[col2].value_counts().head(10).index.tolist())) ]\n",
    "            df3 = pd.crosstab(df2[col1], df2[col2])\n",
    "            df3 = df3+1e-8\n",
    "        else:\n",
    "            df3 = pd.DataFrame(df[col1].value_counts())[:10]\n",
    "        fig,ax = plt.subplots()\n",
    "        fig,rects = mosaic(df3.unstack(),ax=ax, statistic=False, labelizer=InteractionAnalytics.NoLabels, label_rotation=30)\n",
    "        ax.set_ylabel(col1)\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_title('{} vs {}'.format(col1, col2) )\n",
    "    \n",
    "    @staticmethod\n",
    "    def numerical_relations(df, col1, col2):\n",
    "        from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "        x = df[col2]\n",
    "        y = df[col1]\n",
    "        f, ax = plt.subplots(1)\n",
    "\n",
    "        # lowess\n",
    "        ax.scatter(x, y, c='g', s=6)\n",
    "        lowess_results = lowess(y, x)#[:,1]\n",
    "        xs = lowess_results[:, 0]\n",
    "        ys = lowess_results[:, 1]\n",
    "        ax.plot(xs,ys,'red',linewidth=1)\n",
    "\n",
    "        #ols\n",
    "        fit = np.polyfit(x, y, 1)\n",
    "        fit1d = np.poly1d(fit)\n",
    "        ax.plot(x, fit1d(x), '--b')\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_ylabel(col1)\n",
    "        corr = round(scipy.stats.pearsonr(x, y)[0], 6)\n",
    "        ax.set_title('{} vs {}, Correlation {}'.format(col1, col2, corr))\n",
    "    \n",
    "    @staticmethod\n",
    "    def numerical_correlation(df, conf_dict, col1):\n",
    "        from matplotlib.pyplot import quiver, colorbar, clim,  matshow\n",
    "        df2 = df[NumericalColumns].corr(method=col1)\n",
    "        col_names = list(df[NumericalColumns].columns)\n",
    "        fig,ax = plt.subplots(1, 1)\n",
    "        m = ax.matshow(df2, cmap=matplotlib.pyplot.cm.coolwarm)\n",
    "        ax.grid(b=False)\n",
    "        fig.colorbar(m)\n",
    "        ax.set_xticklabels([' '] + col_names) \n",
    "        ax.set_yticklabels([' '] + col_names)\n",
    "\n",
    "    @staticmethod\n",
    "    def numerical_pca(df, conf_dict, col1, col2, col3):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        num_numeric = len(NumericalColumns)\n",
    "        num_pca = num_numeric\n",
    "        xticklabels = ['']\n",
    "        for i in range(1,num_pca+1):\n",
    "            xticklabels+=['Comp'+str(i)]\n",
    "            xticklabels+=['']\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        pca = PCA(n_components=num_pca)\n",
    "        pca.fit(X)\n",
    "        fig, (ax1,ax2) = plt.subplots(1, 2)\n",
    "        ax1.bar(np.arange(1,(num_numeric+1),1),pca.explained_variance_ratio_ )\n",
    "        ax1.set_ylabel('% Variance Explained')\n",
    "        ax1.set_xticklabels(xticklabels)\n",
    "        x_pca_index = int(col2) - 1\n",
    "        y_pca_index = int(col3) - 1\n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca_labels = []\n",
    "        for i in range(1,num_pca+1):\n",
    "            Y_pca_labels.append('PC'+str(i))\n",
    "        Y_pca.columns = Y_pca_labels       \n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1, 'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax2.scatter(\n",
    "               group[Y_pca.columns[x_pca_index]], group[Y_pca.columns[y_pca_index]],label=name,  \n",
    "               c=group['color'],                            \n",
    "               marker='o',                                \n",
    "               s=6)                                       \n",
    "        ax2.set_xlabel(Y_pca.columns[x_pca_index])\n",
    "        ax2.set_ylabel(Y_pca.columns[y_pca_index])\n",
    "        ax2.legend(title=col1, fontsize=14)\n",
    "                \n",
    "    @staticmethod\n",
    "    def nc_relation(df, conf_dict, col1, col2, col3=None):\n",
    "        fig,ax = plt.subplots()\n",
    "        f = df[[col1,col2]].boxplot(by=col2, ax=ax)\n",
    "        mod = ols('{} ~ {}'.format(col1, col2), data=df[[col1, col2]]).fit()\n",
    "        aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "        p_val = round(aov_table['PR(>F)'][0], 6)\n",
    "        status = 'Passed'\n",
    "        color = 'blue'\n",
    "        if p_val < 0.05:\n",
    "            status = 'Rejected'\n",
    "            color = 'red'\n",
    "        fig.suptitle('ho {} (p_value = {})'.format( status, p_val), color=color, fontsize=10)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pca_3d(df, conf_dict, col1, col2,  col3=None):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        pca = PCA(n_components=4)\n",
    "        pca.fit(X)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.view_init(elev=10, azim=int(col2))              \n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca.columns = ['PC1','PC2','PC3','PC4']\n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1,'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax.scatter(\n",
    "               group['PC1'], group['PC2'], group['PC3'], label=name,  \n",
    "               c = group['color'],                            \n",
    "               marker = 'o',                                \n",
    "               s=6)                                      \n",
    "        ax.set_xlabel('PC1', labelpad=18)\n",
    "        ax.set_ylabel('PC2', labelpad=18)\n",
    "        ax.set_zlabel('PC3', labelpad=18)\n",
    "        ax.legend(title=col1, fontsize=10)\n",
    "\n",
    "    @staticmethod\n",
    "    def pca_3d_new(df, conf_dict, col1, col2, col3, col4, col5):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        num_numeric = len(NumericalColumns)\n",
    "        pca = PCA(n_components=num_numeric)\n",
    "        pca.fit(X)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.view_init(elev=10, azim=int(col5))                 \n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca_names = []\n",
    "        for i in range(1, num_numeric+1):\n",
    "            Y_pca_names.append('PC'+str(i))\n",
    "        Y_pca.columns = Y_pca_names\n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1,'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax.scatter(\n",
    "               group[Y_pca_names[int(col2)-1]], group[Y_pca_names[int(col3)-1]], group[Y_pca_names[int(col4)-1]], label=name,  \n",
    "               c = group['color'],                            \n",
    "               marker = 'o',                                \n",
    "               s=6)\n",
    "        ax.set_xlabel(Y_pca_names[int(col2)-1], labelpad=18)\n",
    "        ax.set_ylabel(Y_pca_names[int(col3)-1], labelpad=18)\n",
    "        ax.set_zlabel(Y_pca_names[int(col4)-1], labelpad=18)\n",
    "        ax.legend(title=col1, fontsize=10)\n",
    "        \n",
    "    @staticmethod\n",
    "    def nnc_relation(df, conf_dict, col1, col2, col3):\n",
    "        import itertools\n",
    "        markers = ['x', 'o', '^']\n",
    "        color = itertools.cycle(['r', 'y', 'c', 'y', 'k']) \n",
    "        groups = df[[col1, col2, col3]].groupby(col3)\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.margins(0.05) \n",
    "\n",
    "        for (name, group), marker in zip(groups, itertools.cycle(markers)):\n",
    "            ax.plot(group[col1], group[col2], marker='o', linestyle='', ms=4, label=name)\n",
    "        ax.set_xlabel(col1)\n",
    "        ax.set_ylabel(col2)\n",
    "        ax.legend(numpoints=1, loc='best', title=col3)\n",
    "        \n",
    "class TargetAnalytics():\n",
    "    ReportedVariables = []\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        f, (ax0,ax1) = plt.subplots(1, 2)\n",
    "        df[col1].value_counts().plot(ax=ax0, kind='bar')\n",
    "        ax0.set_title('Bar Plot of {}'.format(col1))\n",
    "        df[col1].value_counts().plot(ax=ax1, kind='pie')\n",
    "        ax1.set_title('Pie Chart of {}'.format(col1))\n",
    "\n",
    "class NumericAnalytics():\n",
    "    @staticmethod\n",
    "    def shapiro_test(x):\n",
    "        #p_val = round(stats.shapiro(x)[1],6)\n",
    "        p_val = stats.shapiro(x)[1]\n",
    "        status = 'passed'\n",
    "        color = 'blue'\n",
    "        if p_val < 0.05:\n",
    "            status = 'failed'\n",
    "            color = 'red'\n",
    "        return status, color, p_val\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        if len(df[col1]) > 5000:\n",
    "            sampleSize = 5000\n",
    "        else:\n",
    "            sampleSize = len(df[col1])\n",
    "        fig, axes = plt.subplots(2,2 , figsize=(11.5, 11.5))\n",
    "        axes = axes.reshape(-1)\n",
    "        df[col1].plot(ax=axes[0], kind='hist')\n",
    "        axes[0].set_title('Histogram of {}'.format(col1))\n",
    "        df[col1].plot(ax=axes[1], kind='kde')\n",
    "        axes[1].set_title('Density Plot of {}'.format(col1))\n",
    "        ax3 = plt.subplot(223)\n",
    "        stats.probplot(df[col1], plot=plt)\n",
    "        axes[2].set_title('QQ Plot of {}'.format(col1))\n",
    "        df[col1].plot(ax=axes[3], kind='box')\n",
    "        axes[3].set_title('Box Plot of {}'.format(col1))\n",
    "        status, color, p_val = NumericAnalytics.shapiro_test(df[col1].sample(sampleSize))\n",
    "        fig.suptitle('Normality test for {} {} (p_value = {})'.format(col1, status, p_val, color=color, fontsize=12))\n",
    "    \n",
    "class CategoricAnalytics():\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        f, (ax0,ax1) = plt.subplots(1,2)\n",
    "        df[col1].value_counts().nlargest(10).plot(ax=ax0, kind='bar')\n",
    "        ax0.set_xlabel(col1)\n",
    "        ax0.set_title('Bar chart of {}'.format(col1))\n",
    "        df[col1].value_counts().nlargest(10).plot(ax=ax1, kind='pie')\n",
    "        ax1.set_title('Pie chart of {}'.format(col1))\n",
    " \n",
    "%matplotlib inline\n",
    "font={'family':'normal','weight':'normal','size':8}\n",
    "matplotlib.rc('font',**font)\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 5.0)\n",
    "matplotlib.rc('xtick', labelsize=9) \n",
    "matplotlib.rc('ytick', labelsize=9)\n",
    "matplotlib.rc('axes', labelsize=10)\n",
    "matplotlib.rc('axes', titlesize=10)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"read and summarize\"></a> Read and Summarize the Data\n",
    "\n",
    "### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Files(direc, files):\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        yield pd.read_csv(direc + f,  delimiter=',', header=0, parse_dates=True, low_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and infer column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m conf_dict \u001b[39m=\u001b[39m  {}\n\u001b[0;32m      7\u001b[0m \u001b[39m# Making sure that we are not reading any extra column\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[39m=\u001b[39m df[[each \u001b[39mfor\u001b[39;00m each \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mUnnamed\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m each]]\n\u001b[0;32m     10\u001b[0m \u001b[39m# Sampling Data if data size is larger than 10k\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df0 \u001b[39m=\u001b[39m df \u001b[39m# df0 is the unsampled data. Will be used in data exploration and analysis where sampling is not needed\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define sample size\n",
    "Sample_Size = 10000\n",
    "\n",
    "# this is used in various places in the code. Origianlly it was a yaml file. But for simplicity, I have converted it to a dictionary\n",
    "conf_dict =  {}\n",
    "    \n",
    "# Making sure that we are not reading any extra column\n",
    "df = df[[each for each in df.columns if 'Unnamed' not in each]]\n",
    "\n",
    "# Sampling Data if data size is larger than 10k\n",
    "df0 = df # df0 is the unsampled data. Will be used in data exploration and analysis where sampling is not needed\n",
    "         # However, keep in mind that your final report will always be based on the sampled data. \n",
    "if Sample_Size < df.shape[0]:\n",
    "    df = df.sample(Sample_Size)\n",
    "\n",
    "# Getting the list of categorical columns if it was not there in the yaml file\n",
    "if 'CategoricalColumns' not in conf_dict:\n",
    "    conf_dict['CategoricalColumns'] = list(set(list(df.select_dtypes(exclude=[np.number]).columns)))\n",
    "\n",
    "# Getting the list of numerical columns if it was not there in the yaml file\n",
    "if 'NumericalColumns' not in conf_dict:\n",
    "    conf_dict['NumericalColumns'] = list(df.select_dtypes(include=[np.number]).columns)    \n",
    "\n",
    "# Exclude columns that we do not need\n",
    "if 'ColumnsToExclude' in conf_dict:\n",
    "    conf_dict['CategoricalColumns'] = list(set(conf_dict['CategoricalColumns'])-set(conf_dict['ColumnsToExclude']))\n",
    "    conf_dict['NumericalColumns'] = list(set(conf_dict['NumericalColumns'])-set(conf_dict['ColumnsToExclude']))\n",
    "\n",
    "# Ordering the categorical variables according to the number of unique categories\n",
    "filtered_cat_columns = []\n",
    "temp_dict = {}\n",
    "\n",
    "for cat_var in conf_dict['CategoricalColumns']:\n",
    "    temp_dict[cat_var] = len(np.unique(df[cat_var]))\n",
    "\n",
    "sorted_x = sorted(temp_dict.items(), key=operator.itemgetter(0), reverse=True)\n",
    "conf_dict['CategoricalColumns'] = [x for (x,y) in sorted_x]\n",
    "ConfUtility.dict_to_htmllist(conf_dict,['Target','CategoricalColumns','NumericalColumns'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the first n (n=5 by default) rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_head(df,NoOfRows):\n",
    "    return HTML(df.head(NoOfRows).style.set_table_attributes(\"class='table'\").render())\n",
    "i = interact(custom_head,df=fixed(df0), NoOfRows=ipywidgets.IntSlider(min=0, max=30, step=1, value=5, description='Number of Rows'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dimensions of the data (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The data has {} Rows and {} columns'.format(df0.shape[0],df0.shape[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the column names of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ','.join(each for each in list(df.columns))\n",
    "print(\"The column names are:\" + col_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The types of columns are:\")\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"descriptive statistics\"></a>Extract Descriptive Statistics of Each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(x):\n",
    "    return len(x.index)-x.count()\n",
    "\n",
    "def num_unique(x):\n",
    "    return len(np.unique(x))\n",
    "\n",
    "temp_df = df0.describe().T\n",
    "missing_df = pd.DataFrame(df0.apply(num_missing, axis=0)) \n",
    "missing_df.columns = ['missing']\n",
    "unq_df = pd.DataFrame(df0.apply(num_unique, axis=0))\n",
    "unq_df.columns = ['unique']\n",
    "types_df = pd.DataFrame(df0.dtypes)\n",
    "types_df.columns = ['DataType']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = temp_df.join(missing_df).join(unq_df).join(types_df)\n",
    "summary_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(types_df.index)\n",
    "num_cols = len(col_names)\n",
    "index = range(num_cols)\n",
    "cat_index = []\n",
    "for i in index:\n",
    "    if col_names[i] in conf_dict['CategoricalColumns']:\n",
    "        cat_index.append(i)\n",
    "summary_df_cat = missing_df.join(unq_df).join(types_df.iloc[cat_index], how='inner') #Only summarize categorical columns\n",
    "summary_df_cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"individual variables\"></a>Explore Individual Variables\n",
    "\n",
    "### Explore the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf_dict['Target'] in conf_dict['CategoricalColumns']:\n",
    "    w1_value = ''\n",
    "    w1 = None  \n",
    "    w1 = widgets.Dropdown(\n",
    "        options=[conf_dict['Target']],\n",
    "        value=conf_dict['Target'],\n",
    "        description='Target Variable:',\n",
    "    )\n",
    "    i = interactive(TargetAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "    hbox = widgets.HBox(i.children[:1])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(TargetAnalytics.custom_barplot(df=df0, col1=w1.value))\n",
    "else:\n",
    "    w1_value = ''\n",
    "    w1 = None\n",
    "    w1 = widgets.Dropdown(\n",
    "            options=[conf_dict['Target']],\n",
    "            value=conf_dict['Target'],\n",
    "            description='Target Variable:',\n",
    "        )\n",
    "    i = interactive(NumericAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "    hbox = widgets.HBox(i.children)\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(NumericAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore individual numeric variables and test for normality (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_value = ''\n",
    "w1 = None\n",
    "w1 = widgets.Dropdown(\n",
    "        options=conf_dict['NumericalColumns'],\n",
    "        value=conf_dict['NumericalColumns'][0],\n",
    "        description='Numeric Variable:',\n",
    "    )\n",
    "\n",
    "i = interactive(NumericAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(NumericAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore individual categorical variables (sorted by frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_value = ''\n",
    "w1 = None\n",
    "\n",
    "w1 = widgets.Dropdown(\n",
    "    options = conf_dict['CategoricalColumns'],\n",
    "    value = conf_dict['CategoricalColumns'][0],\n",
    "    description = 'Categorical Variable:',\n",
    ")\n",
    "\n",
    "\n",
    "i = interactive(CategoricAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(CategoricAnalytics.custom_barplot(df=df0, col1=w1.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"multiple variables\"></a>Explore Interactions Between Variables\n",
    "\n",
    "### <a name=\"rank variables\"></a>Rank variables based on linear relationships with reference variable (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = [conf_dict['Target']] + conf_dict['NumericalColumns'] + conf_dict['CategoricalColumns'] \n",
    "cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "w1 = widgets.Dropdown(    \n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Ref Var:'\n",
    ")\n",
    "w2 = ipywidgets.Text(value=\"5\", description='Top Num Vars:')\n",
    "w3 = ipywidgets.Text(value=\"5\", description='Top Cat Vars:')\n",
    "i = interactive(InteractionAnalytics.rank_associations, df=fixed(df),conf_dict=fixed(conf_dict), col1=w1, col2=w2, col3=w3)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.rank_associations(df=df, conf_dict=conf_dict, col1=w1.value, col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two categorical\"></a>Explore interactions between categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if conf_dict['Target'] in conf_dict['CategoricalColumns']:\n",
    "    cols_list = [conf_dict['Target']] + conf_dict['CategoricalColumns'] \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = conf_dict['CategoricalColumns']\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Categorical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[1],\n",
    "    description='Categorical Var 2:'\n",
    ")\n",
    "\n",
    "i = interactive(InteractionAnalytics.categorical_relations, df=fixed(df), col1=w1, col2=w2)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.categorical_relations(df=df0, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two numerical\"></a>Explore interactions between numerical variables (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if conf_dict['Target'] in conf_dict['NumericalColumns']:\n",
    "    cols_list = [conf_dict['Target']] + conf_dict['NumericalColumns'] \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = conf_dict['NumericalColumns']\n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Numerical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[1],\n",
    "    description='Numerical Var 2:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.numerical_relations, df=fixed(df), col1=w1, col2=w2)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.numerical_relations(df, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore correlation matrix between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = None\n",
    "w1 = widgets.Dropdown(\n",
    "    options=['pearson','kendall','spearman'],\n",
    "    value='pearson',\n",
    "    description='Correlation Method:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.numerical_correlation, df=fixed(df), conf_dict=fixed(conf_dict), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.numerical_correlation(df0, conf_dict=conf_dict, col1=w1.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"numerical and categorical\"></a>Explore interactions between numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if conf_dict['Target'] in conf_dict['NumericalColumns']:\n",
    "    cols_list = [conf_dict['Target']] + conf_dict['NumericalColumns'] #Make target the default reference variable\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) #remove variables that might be duplicates with target\n",
    "else:\n",
    "    cols_list = conf_dict['NumericalColumns']\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Numerical Variable:'\n",
    ")\n",
    "\n",
    "if conf_dict['Target'] in conf_dict['CategoricalColumns']:\n",
    "    cols_list = [conf_dict['Target']] + conf_dict['CategoricalColumns'] #Make target the default reference variable\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) #remove variables that might be duplicates with target\n",
    "else:\n",
    "    cols_list = conf_dict['CategoricalColumns']\n",
    "    \n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Categorical Variable:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.nc_relation, df=fixed(df),conf_dict=fixed(conf_dict), col1=w1, col2=w2, col3=fixed(w3))\n",
    "hbox = widgets.HBox(i.children)\n",
    "display( hbox )\n",
    "hbox.on_displayed(InteractionAnalytics.nc_relation(df0, conf_dict, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two numerical and categorical\"></a>Explore interactions between two numerical variables and a categorical variable (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3 = None, None, None\n",
    "\n",
    "if conf_dict['Target'] in conf_dict['NumericalColumns']:\n",
    "    cols_list = [conf_dict['Target']] + conf_dict['NumericalColumns'] \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = conf_dict['NumericalColumns']\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[0],\n",
    "    description = 'Numerical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[1],\n",
    "    description = 'Numerical Var 2:'\n",
    ")\n",
    "\n",
    "if conf_dict['Target'] in conf_dict['CategoricalColumns']:\n",
    "    cols_list = [conf_dict['Target']] + conf_dict['CategoricalColumns'] \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = conf_dict['CategoricalColumns']\n",
    "    \n",
    "w3 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[0],\n",
    "    description = 'Legend Cat Var:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.nnc_relation, df=fixed(df),conf_dict=fixed(conf_dict), col1=w1, col2=w2, col3=w3)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.nnc_relation(df, conf_dict, col1=w1.value,col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"pca\"></a>Visualize numerical data by projecting to principal component spaces (on sampled data)\n",
    "\n",
    "### Project data to 2-D principal component space (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_numeric = len(conf_dict['NumericalColumns'])\n",
    "if  num_numeric > 3:\n",
    "    \n",
    "    w1, w2, w3 = None, None, None\n",
    "    if conf_dict['Target'] in conf_dict['CategoricalColumns']:\n",
    "        cols_list = [conf_dict['Target']] + conf_dict['CategoricalColumns'] \n",
    "        cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "    else:\n",
    "        cols_list = conf_dict['CategoricalColumns']\n",
    "    w1 = widgets.Dropdown(\n",
    "        options = cols_list,\n",
    "        value = cols_list[0],\n",
    "        description = 'Legend Variable:',\n",
    "        width = 10\n",
    "    )\n",
    "    w2 = widgets.Dropdown(\n",
    "        options = [str(x) for x in np.arange(1,num_numeric+1)],\n",
    "        value = '1',\n",
    "        width = 1,\n",
    "        description='PC at X-Axis:'\n",
    "    )\n",
    "    w3 = widgets.Dropdown(\n",
    "        options = [str(x) for x in np.arange(1,num_numeric+1)],\n",
    "        value = '2',\n",
    "        description = 'PC at Y-Axis:'\n",
    "    )\n",
    "    i = interactive(InteractionAnalytics.numerical_pca, df=fixed(df),conf_dict=fixed(conf_dict), col1=w1, col2=w2, col3=w3)\n",
    "    hbox = widgets.HBox(i.children[:3])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(InteractionAnalytics.numerical_pca(df, conf_dict=conf_dict, col1=w1.value, col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project data to 3-D principal component space (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(conf_dict['NumericalColumns']) > 3:\n",
    "    if conf_dict['Target'] in conf_dict['CategoricalColumns']:\n",
    "        cols_list = [conf_dict['Target']] + conf_dict['CategoricalColumns'] \n",
    "        cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "    else:\n",
    "        cols_list = conf_dict['CategoricalColumns']\n",
    "    w1, w2 = None, None\n",
    "    w1 = widgets.Dropdown(\n",
    "        options=cols_list,\n",
    "        value=cols_list[0],\n",
    "        description='Legend Variable:'\n",
    "    )\n",
    "    w2 = ipywidgets.IntSlider(min=-180, max=180, step=5, value=30, description='Angle')\n",
    "    i = interactive(InteractionAnalytics.pca_3d, df=fixed(df), conf_dict=fixed(conf_dict),col1=w1, col2=w2, col3=fixed(w3))\n",
    "    hbox=widgets.HBox(i.children[:2])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(InteractionAnalytics.pca_3d(df,conf_dict,col1=w1.value,col2=w2.value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
